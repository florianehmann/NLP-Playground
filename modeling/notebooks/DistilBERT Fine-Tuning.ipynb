{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d29c97ee-ad39-4fe6-b43d-3eb5a6a37e1c",
   "metadata": {},
   "source": [
    "In this notebook, we use DistilBERT with a custom classification head and fine-tune it to the emotion dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a58707-97ca-4301-858b-5ec03481030e",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba163d7-9c23-4563-ba22-82a97c3299e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8e4b2e2-babf-47a8-a6d5-c95d308cbfbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emotion = load_dataset('emotion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e7953d-2086-4540-b610-781c277098b1",
   "metadata": {},
   "source": [
    "# Load the DistilBERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8abb3d7-10fb-4dd8-a462-5938338638f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d39874c8-5390-49e2-b533-019388f9fc09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a7077c4-eee2-421c-a3d1-3c67d5ba1112",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'the', 'di', '##sti', '##lbert', 'token', '##izer', 'is', 'working', '!', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(\n",
    "    tokenizer(\"The DistilBERT Tokenizer is working!\").input_ids\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ad12d1-4884-4e9b-bcc2-33fd65db6564",
   "metadata": {},
   "source": [
    "Now we can create a `tokenize` function that tokenizes the dataset in the format that is required by the DistilBERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "700c9f60-8382-43be-af42-5085faa76017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1439fae6-77b0-421a-a440-93dc054aa5d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1045, 2064, 2175, 2013, 3110, 2061, 20625, 2000, 2061, 9636, 17772, 2074, 2013, 2108, 2105, 2619, 2040, 14977, 1998, 2003, 8300, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(emotion['train'][0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "188ede21-e7e7-400e-9bd2-32419a7fd687",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94fbfb3c839b4f0d9d6ebf1af61ff869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "819c2745835e4d3782ffbcdfb6080075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c1f27faeec4a23bb26b72321d7003e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotion_tokenized = emotion.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8165b6a5-5849-4441-a3fe-585de0088f5a",
   "metadata": {},
   "source": [
    "This creates the additional colmuns `input_ids` and `attention_mask` in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efbb26d3-6a24-49f3-beb8-09564f98754f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 16000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(emotion_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaa61a1-8825-4af3-a593-9f86f6233125",
   "metadata": {},
   "source": [
    "# Use DistilBERT with a Custom Classification Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aabb307-fdbc-4ba8-9a2c-e9522d401967",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b79dc8c2-95f3-4ff3-8067-8ec85d390081",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = emotion['train'].features['label'].names\n",
    "num_labels = len(labels)\n",
    "model = (\n",
    "    AutoModelForSequenceClassification\n",
    "    .from_pretrained(model_ckpt, num_labels=num_labels)\n",
    "    .to(device)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f892c7f-d854-4f64-aea8-49f8735bdcea",
   "metadata": {},
   "source": [
    "## Define Quality Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "491582c4-e2e9-4200-80cb-28aca2994677",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb46ccbc-6f8f-44d1-937b-8bee79bdf12f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    \n",
    "    \n",
    "    return {'accuracy': acc, 'f1': f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4513fa41-50c2-4409-a1be-b7fbce09581c",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "941bee3b-0b48-45b8-a694-470dd03df6f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "batch_size = 64\n",
    "logging_steps = len(emotion_tokenized['train']) // batch_size\n",
    "model_name = f\"{model_ckpt}-finetuned-emotion\"\n",
    "output_dir = os.path.join('../models', model_name)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy='epoch',\n",
    "    disable_tqdm=False,\n",
    "    logging_steps=logging_steps,\n",
    "    push_to_hub=False,\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    log_level='error',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2dcceb8-2b89-49b2-827f-82e6be1f025f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 03:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.803800</td>\n",
       "      <td>0.293734</td>\n",
       "      <td>0.909500</td>\n",
       "      <td>0.908724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.223000</td>\n",
       "      <td>0.187521</td>\n",
       "      <td>0.927000</td>\n",
       "      <td>0.927743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.154900</td>\n",
       "      <td>0.170307</td>\n",
       "      <td>0.931500</td>\n",
       "      <td>0.931568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=750, training_loss=0.3939066619873047, metrics={'train_runtime': 181.071, 'train_samples_per_second': 265.089, 'train_steps_per_second': 4.142, 'total_flos': 1080514292544000.0, 'train_loss': 0.3939066619873047, 'epoch': 3.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(model=model, args=training_args, compute_metrics=compute_metrics,\n",
    "                  train_dataset=emotion_tokenized['train'],\n",
    "                  eval_dataset=emotion_tokenized['validation'],\n",
    "                  tokenizer=tokenizer)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83268415-7606-4277-81ee-d1b654e72f9e",
   "metadata": {},
   "source": [
    "# Push the Model to Huggingface Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "477ead8a-77cc-4c78-a8dc-9ad7e314adb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "485570b876b84518b34575e9f9543026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49332ab8741c42ebae82b719df23769c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145afafa2edb4baaa62f5987b053ce0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/florianehmann/distilbert-base-uncased-finetuned-emotion/tree/main/'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(commit_message='Training completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbccd753-7b98-496b-85cd-6dce219cfd2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.save_model(output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed37442-da39-4125-b3c6-bfd195b74cee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
